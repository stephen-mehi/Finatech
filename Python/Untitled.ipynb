{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "absent-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.config.list_physical_devices('GPU')) \n",
    "\n",
    "# CLEAN UP MEMORY\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "about-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             close        date         high          low         open  \\\n",
      "0       454.914024  1604880000   455.544267   454.056224   454.097939   \n",
      "1       453.433040  1604880300   454.678762   453.038198   454.678762   \n",
      "2       452.669440  1604880600   454.500000   452.669440   453.671881   \n",
      "3       451.535630  1604880900   453.007440   451.132360   452.499455   \n",
      "4       452.634457  1604881200   453.000000   451.939406   451.939406   \n",
      "...            ...         ...          ...          ...          ...   \n",
      "43065  2072.103614  1617778800  2089.056150  2071.007976  2088.562283   \n",
      "43066  2072.088014  1617779100  2075.983447  2065.557520  2072.103614   \n",
      "43067  2077.117034  1617779400  2077.875883  2072.175936  2073.086013   \n",
      "43068  2072.138063  1617779700  2077.886044  2069.025950  2077.207710   \n",
      "43069  2076.864882  1617780000  2076.864882  2071.103559  2072.761413   \n",
      "\n",
      "       quoteVolume         volume  weightedAverage  \n",
      "0         5.931550    2695.082042       454.363902  \n",
      "1        31.188132   14153.943388       453.824655  \n",
      "2        15.949800    7233.596169       453.522696  \n",
      "3        60.272036   27249.010255       452.100379  \n",
      "4        18.631152    8434.599566       452.714873  \n",
      "...            ...            ...              ...  \n",
      "43065    94.729330  196892.398604      2078.473465  \n",
      "43066   138.657571  287065.857383      2070.322271  \n",
      "43067   214.512014  445186.640469      2075.345956  \n",
      "43068   147.437182  305655.581256      2073.124147  \n",
      "43069   157.141034  325893.919288      2073.894453  \n",
      "\n",
      "[43070 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#READ DATA FROM FILE\n",
    "dataset=pd.read_csv(\"C:/ProgramData/ETH/TrainingData/training.csv\", sep=',',header=0)\n",
    "#PRINT DATA\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bored-louisiana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    close      date      high       low      open  \\\n",
      "close            1.000000  0.946695  0.999981  0.999979  0.999963   \n",
      "date             0.946695  1.000000  0.946588  0.946822  0.946687   \n",
      "high             0.999981  0.946588  1.000000  0.999963  0.999981   \n",
      "low              0.999979  0.946822  0.999963  1.000000  0.999976   \n",
      "open             0.999963  0.946687  0.999981  0.999976  1.000000   \n",
      "quoteVolume      0.026433 -0.009313  0.029006  0.023458  0.026770   \n",
      "volume           0.253403  0.196249  0.255916  0.250493  0.253709   \n",
      "weightedAverage  0.999989  0.946708  0.999989  0.999989  0.999983   \n",
      "\n",
      "                 quoteVolume    volume  weightedAverage  \n",
      "close               0.026433  0.253403         0.999989  \n",
      "date               -0.009313  0.196249         0.946708  \n",
      "high                0.029006  0.255916         0.999989  \n",
      "low                 0.023458  0.250493         0.999989  \n",
      "open                0.026770  0.253709         0.999983  \n",
      "quoteVolume         1.000000  0.917269         0.026176  \n",
      "volume              0.917269  1.000000         0.253152  \n",
      "weightedAverage     0.026176  0.253152         1.000000  \n"
     ]
    }
   ],
   "source": [
    "#CONDUCT PEARSON CORRELATION\n",
    "correlation_matrix = dataset.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "regular-wrist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the heatmap\n",
    "sns.heatmap(correlation_matrix, xticklabels=correlation_matrix.columns, yticklabels=correlation_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "multiple-angle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              high          low         open  weightedAverage        close\n",
      "0       455.544267   454.056224   454.097939       454.363902   454.914024\n",
      "1       454.678762   453.038198   454.678762       453.824655   453.433040\n",
      "2       454.500000   452.669440   453.671881       453.522696   452.669440\n",
      "3       453.007440   451.132360   452.499455       452.100379   451.535630\n",
      "4       453.000000   451.939406   451.939406       452.714873   452.634457\n",
      "...            ...          ...          ...              ...          ...\n",
      "43065  2089.056150  2071.007976  2088.562283      2078.473465  2072.103614\n",
      "43066  2075.983447  2065.557520  2072.103614      2070.322271  2072.088014\n",
      "43067  2077.875883  2072.175936  2073.086013      2075.345956  2077.117034\n",
      "43068  2077.886044  2069.025950  2077.207710      2073.124147  2072.138063\n",
      "43069  2076.864882  2071.103559  2072.761413      2073.894453  2076.864882\n",
      "\n",
      "[43070 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#SELECT FEATURES AND TARGET\n",
    "data = dataset[[\"high\",\"low\",\"open\",\"weightedAverage\", \"close\"]]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "impossible-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALE DATA \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brilliant-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE MODEL CREATION METHOD. ENABLES EASY HYPER PARAM TUNING\n",
    "def build_model(inputs, neurons, activ_func, dropout, loss, optimizer):\n",
    "    \"\"\"\n",
    "    inputs: input data as numpy array\n",
    "    output_size: number of predictions per input sample\n",
    "    neurons: number of neurons/ units in the LSTM layer\n",
    "    active_func: Activation function to be used in LSTM layers and Dense layer\n",
    "    dropout: dropout ration, default is 0.25\n",
    "    loss: loss function for calculating the gradient\n",
    "    optimizer: type of optimizer to backpropagate the gradient\n",
    "    \n",
    "    This function will build 3 layered RNN model with LSTM cells with dripouts after each LSTM layer \n",
    "    and finally a dense layer to produce the output using keras' sequential model.\n",
    "    Return: Keras sequential model and model summary\n",
    "    \"\"\"\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(neurons, return_sequences=False, input_shape=(inputs.shape[1], inputs.shape[2]), activation=activ_func))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.Dense(units=inputs.shape[2]))\n",
    "    #model.add(layers.Dense(units=1))\n",
    "    model.add(layers.Activation(activ_func))\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "requested-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(training_split, data):\n",
    "    # split into train and test sets\n",
    "    train_size = int(len(data) * training_split)\n",
    "    test_size = len(data) - train_size\n",
    "    train, test = data[0:train_size,:], data[train_size:len(data),:]\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opponent-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences_multivariate_output(sequences, look_back, look_forward):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # end index of lookback window\n",
    "        lookback_end_index = i + look_back\n",
    "        lookforward_end_index = i + look_back + look_forward\n",
    "        # exit if we are beyond the dataset\n",
    "        if lookforward_end_index > len(sequences)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern. input is lookback window of data, output is next step of data\n",
    "        seq_x, seq_y = sequences[i:lookback_end_index, :], sequences[lookback_end_index:lookforward_end_index, :]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "            \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "delayed-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INIT HYPER PARAMS\n",
    "neurons = 512\n",
    "activation_function = 'tanh'\n",
    "loss = 'mse'\n",
    "optimizer=\"adam\"\n",
    "dropout = 0.2\n",
    "batch_size = 12\n",
    "epochs = 150\n",
    "#epochs = 1\n",
    "training_split = 0.99\n",
    "look_back = 20\n",
    "look_forward = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ongoing-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DATA FOR TRAINING\n",
    "train_data, test_data = split_data(training_split, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "potential-marsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training features shape == (42618, 20, 5).\n",
      "training targets shape == (42618, 1, 5).\n",
      "testing features shape == (410, 20, 5).\n",
      "testing features shape == (410, 1, 5).\n",
      "X_TRAIN\n",
      "[[[0.01129529 0.01174612 0.01098914 0.01106678 0.01139118]\n",
      "  [0.01079006 0.0111495  0.0113287  0.01075192 0.01052513]\n",
      "  [0.01068571 0.01093338 0.01074005 0.01057561 0.01007858]\n",
      "  ...\n",
      "  [0.01157216 0.01289617 0.01211199 0.01203291 0.01203711]\n",
      "  [0.01157241 0.01256473 0.01178137 0.01202523 0.01203736]\n",
      "  [0.01184735 0.01275722 0.0123876  0.01227317 0.0119784 ]]\n",
      "\n",
      " [[0.01079006 0.0111495  0.0113287  0.01075192 0.01052513]\n",
      "  [0.01068571 0.01093338 0.01074005 0.01057561 0.01007858]\n",
      "  [0.00981445 0.01003257 0.01005462 0.00974514 0.00941555]\n",
      "  ...\n",
      "  [0.01157241 0.01256473 0.01178137 0.01202523 0.01203736]\n",
      "  [0.01184735 0.01275722 0.0123876  0.01227317 0.0119784 ]\n",
      "  [0.01151345 0.01271817 0.01205319 0.01191385 0.0118595 ]]\n",
      "\n",
      " [[0.01068571 0.01093338 0.01074005 0.01057561 0.01007858]\n",
      "  [0.00981445 0.01003257 0.01005462 0.00974514 0.00941555]\n",
      "  [0.00981011 0.01050554 0.0097272  0.01010394 0.01005812]\n",
      "  ...\n",
      "  [0.01184735 0.01275722 0.0123876  0.01227317 0.0119784 ]\n",
      "  [0.01151345 0.01271817 0.01205319 0.01191385 0.0118595 ]\n",
      "  [0.01132193 0.0120128  0.01186138 0.01161379 0.01115565]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.97019615 0.96985308 0.97219964 0.96877219 0.97134777]\n",
      "  [0.97189081 0.97273081 0.97068888 0.97124091 0.97315889]\n",
      "  [0.97441664 0.9743963  0.97297102 0.97250106 0.97605889]\n",
      "  ...\n",
      "  [0.9718444  0.97400121 0.97324809 0.9707678  0.9730055 ]\n",
      "  [0.97334351 0.97589553 0.97296598 0.97195617 0.97436199]\n",
      "  [0.97380423 0.97661445 0.97395754 0.97355193 0.97575889]]\n",
      "\n",
      " [[0.97189081 0.97273081 0.97068888 0.97124091 0.97315889]\n",
      "  [0.97441664 0.9743963  0.97297102 0.97250106 0.97605889]\n",
      "  [0.97373835 0.97699602 0.97531991 0.97332301 0.9752852 ]\n",
      "  ...\n",
      "  [0.97334351 0.97589553 0.97296598 0.97195617 0.97436199]\n",
      "  [0.97380423 0.97661445 0.97395754 0.97355193 0.97575889]\n",
      "  [0.97493859 0.97824278 0.97557031 0.97468433 0.97648845]]\n",
      "\n",
      " [[0.97441664 0.9743963  0.97297102 0.97250106 0.97605889]\n",
      "  [0.97373835 0.97699602 0.97531991 0.97332301 0.9752852 ]\n",
      "  [0.97548014 0.97775291 0.97461206 0.97508752 0.97677727]\n",
      "  ...\n",
      "  [0.97380423 0.97661445 0.97395754 0.97355193 0.97575889]\n",
      "  [0.97493859 0.97824278 0.97557031 0.97468433 0.97648845]\n",
      "  [0.97633512 0.97894916 0.97694932 0.97602447 0.97608301]]]\n",
      "Y_TRAIN\n",
      "[[[0.01151345 0.01271817 0.01205319 0.01191385 0.0118595 ]]\n",
      "\n",
      " [[0.01132193 0.0120128  0.01186138 0.01161379 0.01115565]]\n",
      "\n",
      " [[0.01090405 0.01177057 0.01109361 0.01102964 0.01116337]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.97493859 0.97824278 0.97557031 0.97468433 0.97648845]]\n",
      "\n",
      " [[0.97633512 0.97894916 0.97694932 0.97602447 0.97608301]]\n",
      "\n",
      " [[0.97680806 0.97778346 0.97574385 0.97649229 0.97684214]]]\n"
     ]
    }
   ],
   "source": [
    "#SHAPE DATA FOR LSTM INPUT\n",
    "x_train, y_train = split_sequences_multivariate_output(train_data, look_back, look_forward)\n",
    "x_test, y_test = split_sequences_multivariate_output(test_data, look_back, look_forward)\n",
    "\n",
    "#PRINT DATA SHAPE\n",
    "print('training features shape == {}.'.format(x_train.shape))\n",
    "print('training targets shape == {}.'.format(y_train.shape))\n",
    "print('testing features shape == {}.'.format(x_test.shape))\n",
    "print('testing features shape == {}.'.format(y_test.shape))\n",
    "\n",
    "print(\"X_TRAIN\")\n",
    "print(x_train)\n",
    "print(\"Y_TRAIN\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "worst-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY NEEDS TO HAPPEN IF LOOK FORWARD IS 1\n",
    "#y_train =  np.reshape(y_train, (y_train.shape[0], 1, y_train.shape[1]))\n",
    "#y_test =  np.reshape(y_test, (y_test.shape[0], 1, y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dominant-change",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training features shape == (42618, 20, 5).\n",
      "training targets shape == (42618, 1, 5).\n",
      "testing features shape == (410, 20, 5).\n",
      "testing features shape == (410, 1, 5).\n",
      "X_TRAIN\n",
      "[[[0.01129529 0.01174612 0.01098914 0.01106678 0.01139118]\n",
      "  [0.01079006 0.0111495  0.0113287  0.01075192 0.01052513]\n",
      "  [0.01068571 0.01093338 0.01074005 0.01057561 0.01007858]\n",
      "  ...\n",
      "  [0.01157216 0.01289617 0.01211199 0.01203291 0.01203711]\n",
      "  [0.01157241 0.01256473 0.01178137 0.01202523 0.01203736]\n",
      "  [0.01184735 0.01275722 0.0123876  0.01227317 0.0119784 ]]\n",
      "\n",
      " [[0.01079006 0.0111495  0.0113287  0.01075192 0.01052513]\n",
      "  [0.01068571 0.01093338 0.01074005 0.01057561 0.01007858]\n",
      "  [0.00981445 0.01003257 0.01005462 0.00974514 0.00941555]\n",
      "  ...\n",
      "  [0.01157241 0.01256473 0.01178137 0.01202523 0.01203736]\n",
      "  [0.01184735 0.01275722 0.0123876  0.01227317 0.0119784 ]\n",
      "  [0.01151345 0.01271817 0.01205319 0.01191385 0.0118595 ]]\n",
      "\n",
      " [[0.01068571 0.01093338 0.01074005 0.01057561 0.01007858]\n",
      "  [0.00981445 0.01003257 0.01005462 0.00974514 0.00941555]\n",
      "  [0.00981011 0.01050554 0.0097272  0.01010394 0.01005812]\n",
      "  ...\n",
      "  [0.01184735 0.01275722 0.0123876  0.01227317 0.0119784 ]\n",
      "  [0.01151345 0.01271817 0.01205319 0.01191385 0.0118595 ]\n",
      "  [0.01132193 0.0120128  0.01186138 0.01161379 0.01115565]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.97019615 0.96985308 0.97219964 0.96877219 0.97134777]\n",
      "  [0.97189081 0.97273081 0.97068888 0.97124091 0.97315889]\n",
      "  [0.97441664 0.9743963  0.97297102 0.97250106 0.97605889]\n",
      "  ...\n",
      "  [0.9718444  0.97400121 0.97324809 0.9707678  0.9730055 ]\n",
      "  [0.97334351 0.97589553 0.97296598 0.97195617 0.97436199]\n",
      "  [0.97380423 0.97661445 0.97395754 0.97355193 0.97575889]]\n",
      "\n",
      " [[0.97189081 0.97273081 0.97068888 0.97124091 0.97315889]\n",
      "  [0.97441664 0.9743963  0.97297102 0.97250106 0.97605889]\n",
      "  [0.97373835 0.97699602 0.97531991 0.97332301 0.9752852 ]\n",
      "  ...\n",
      "  [0.97334351 0.97589553 0.97296598 0.97195617 0.97436199]\n",
      "  [0.97380423 0.97661445 0.97395754 0.97355193 0.97575889]\n",
      "  [0.97493859 0.97824278 0.97557031 0.97468433 0.97648845]]\n",
      "\n",
      " [[0.97441664 0.9743963  0.97297102 0.97250106 0.97605889]\n",
      "  [0.97373835 0.97699602 0.97531991 0.97332301 0.9752852 ]\n",
      "  [0.97548014 0.97775291 0.97461206 0.97508752 0.97677727]\n",
      "  ...\n",
      "  [0.97380423 0.97661445 0.97395754 0.97355193 0.97575889]\n",
      "  [0.97493859 0.97824278 0.97557031 0.97468433 0.97648845]\n",
      "  [0.97633512 0.97894916 0.97694932 0.97602447 0.97608301]]]\n",
      "Y_TRAIN\n",
      "[[[0.01151345 0.01271817 0.01205319 0.01191385 0.0118595 ]]\n",
      "\n",
      " [[0.01132193 0.0120128  0.01186138 0.01161379 0.01115565]]\n",
      "\n",
      " [[0.01090405 0.01177057 0.01109361 0.01102964 0.01116337]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.97493859 0.97824278 0.97557031 0.97468433 0.97648845]]\n",
      "\n",
      " [[0.97633512 0.97894916 0.97694932 0.97602447 0.97608301]]\n",
      "\n",
      " [[0.97680806 0.97778346 0.97574385 0.97649229 0.97684214]]]\n"
     ]
    }
   ],
   "source": [
    "#PRINT DATA SHAPE\n",
    "print('training features shape == {}.'.format(x_train.shape))\n",
    "print('training targets shape == {}.'.format(y_train.shape))\n",
    "print('testing features shape == {}.'.format(x_test.shape))\n",
    "print('testing features shape == {}.'.format(y_test.shape))\n",
    "\n",
    "print(\"X_TRAIN\")\n",
    "print(x_train)\n",
    "print(\"Y_TRAIN\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-initial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 512)               1060864   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,063,429\n",
      "Trainable params: 1,063,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "3552/3552 [==============================] - 23s 6ms/step - loss: 1.1752e-04 - mae: 0.0068 - val_loss: 7.0336e-04 - val_mae: 0.0252\n",
      "Epoch 2/150\n",
      "3552/3552 [==============================] - 21s 6ms/step - loss: 0.0262 - mae: 0.0711 - val_loss: 0.0012 - val_mae: 0.0339\n",
      "Epoch 3/150\n",
      "3552/3552 [==============================] - 21s 6ms/step - loss: 0.0113 - mae: 0.0294 - val_loss: 0.0012 - val_mae: 0.0331\n",
      "Epoch 4/150\n",
      "3552/3552 [==============================] - 22s 6ms/step - loss: 0.0213 - mae: 0.0496 - val_loss: 8.6071e-04 - val_mae: 0.0280\n",
      "Epoch 5/150\n",
      "3552/3552 [==============================] - 21s 6ms/step - loss: 0.0242 - mae: 0.0625 - val_loss: 0.0011 - val_mae: 0.0321\n",
      "Epoch 6/150\n",
      "3552/3552 [==============================] - 21s 6ms/step - loss: 0.0107 - mae: 0.0336 - val_loss: 9.1079e-04 - val_mae: 0.0290\n",
      "Epoch 7/150\n",
      "3552/3552 [==============================] - 25s 7ms/step - loss: 0.0101 - mae: 0.0357 - val_loss: 7.6505e-04 - val_mae: 0.0263\n",
      "Epoch 8/150\n",
      "3552/3552 [==============================] - 21s 6ms/step - loss: 0.0163 - mae: 0.0434 - val_loss: 7.9644e-04 - val_mae: 0.0269\n",
      "Epoch 9/150\n",
      "3552/3552 [==============================] - 20s 6ms/step - loss: 0.0029 - mae: 0.0307 - val_loss: 8.2437e-04 - val_mae: 0.0274\n",
      "Epoch 10/150\n",
      "3552/3552 [==============================] - 21s 6ms/step - loss: 0.0060 - mae: 0.0345 - val_loss: 8.5521e-04 - val_mae: 0.0280\n",
      "Epoch 11/150\n",
      "3552/3552 [==============================] - 24s 7ms/step - loss: 0.0033 - mae: 0.0253 - val_loss: 8.8742e-04 - val_mae: 0.0286\n",
      "Epoch 12/150\n",
      "3552/3552 [==============================] - 23s 7ms/step - loss: 0.0024 - mae: 0.0239 - val_loss: 9.2634e-04 - val_mae: 0.0293\n",
      "Epoch 13/150\n",
      "3552/3552 [==============================] - 21s 6ms/step - loss: 0.0028 - mae: 0.0273 - val_loss: 8.5988e-04 - val_mae: 0.0282\n",
      "Epoch 14/150\n",
      "3552/3552 [==============================] - 20s 6ms/step - loss: 0.0018 - mae: 0.0226 - val_loss: 8.3012e-04 - val_mae: 0.0276\n",
      "Epoch 15/150\n",
      "3552/3552 [==============================] - 23s 7ms/step - loss: 0.0016 - mae: 0.0206 - val_loss: 7.1471e-04 - val_mae: 0.0255\n",
      "Epoch 16/150\n",
      "3552/3552 [==============================] - 21s 6ms/step - loss: 0.0012 - mae: 0.0194 - val_loss: 3.4384e-04 - val_mae: 0.0170\n",
      "Epoch 17/150\n",
      "3552/3552 [==============================] - 22s 6ms/step - loss: 8.7573e-04 - mae: 0.0171 - val_loss: 8.9014e-04 - val_mae: 0.0287\n",
      "Epoch 18/150\n",
      "3552/3552 [==============================] - 21s 6ms/step - loss: 7.5555e-04 - mae: 0.0165 - val_loss: 6.9026e-04 - val_mae: 0.0251\n",
      "Epoch 19/150\n",
      "3552/3552 [==============================] - 21s 6ms/step - loss: 6.1947e-04 - mae: 0.0152 - val_loss: 6.9498e-04 - val_mae: 0.0252\n",
      "Epoch 20/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 5.0557e-04 - mae: 0.0142 - val_loss: 7.0310e-04 - val_mae: 0.0254\n",
      "Epoch 21/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 4.8353e-04 - mae: 0.0139 - val_loss: 5.4409e-04 - val_mae: 0.0221\n",
      "Epoch 22/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 3.1608e-04 - mae: 0.0123 - val_loss: 7.1389e-05 - val_mae: 0.0069\n",
      "Epoch 23/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 4.6592e-04 - mae: 0.0120 - val_loss: 5.7962e-04 - val_mae: 0.0228\n",
      "Epoch 24/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 2.8419e-04 - mae: 0.0115 - val_loss: 5.1529e-04 - val_mae: 0.0215\n",
      "Epoch 25/150\n",
      "3552/3552 [==============================] - 19s 5ms/step - loss: 2.8560e-04 - mae: 0.0114 - val_loss: 5.5663e-04 - val_mae: 0.0224\n",
      "Epoch 26/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 2.3189e-04 - mae: 0.0108 - val_loss: 7.5329e-04 - val_mae: 0.0263\n",
      "Epoch 27/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 2.3067e-04 - mae: 0.0108 - val_loss: 6.3691e-04 - val_mae: 0.0240\n",
      "Epoch 28/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 2.0071e-04 - mae: 0.0103 - val_loss: 5.4659e-04 - val_mae: 0.0222\n",
      "Epoch 29/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 1.8842e-04 - mae: 0.0101 - val_loss: 5.1342e-04 - val_mae: 0.0215\n",
      "Epoch 30/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 2.0020e-04 - mae: 0.0101 - val_loss: 2.8468e-04 - val_mae: 0.0154\n",
      "Epoch 31/150\n",
      "3552/3552 [==============================] - 18s 5ms/step - loss: 1.9119e-04 - mae: 0.0099 - val_loss: 5.2964e-04 - val_mae: 0.0218\n",
      "Epoch 32/150\n",
      "3481/3552 [============================>.] - ETA: 0s - loss: 1.8907e-04 - mae: 0.0098"
     ]
    }
   ],
   "source": [
    "# CLEAN UP MEMORY\n",
    "gc.collect()\n",
    "# random seed for reproducibility\n",
    "np.random.seed(404)\n",
    "# initialise model architecture\n",
    "model = build_model(x_train, neurons=neurons, activ_func=activation_function, dropout=dropout, loss=loss, optimizer=optimizer)\n",
    "# train model on data\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(x_test, y_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT LOSS\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT LOSS\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('model mae')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERFORM PREDICTIONS\n",
    "train_predict = model.predict(x_train)\n",
    "test_predict = model.predict(x_test)\n",
    "print(train_predict.shape)\n",
    "print(test_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_shaped = scaler.inverse_transform(np.array(test_predict))\n",
    "train_predict_shaped = scaler.inverse_transform(np.array(train_predict))\n",
    "test_predict_shaped = test_predict_shaped[:,4:5]\n",
    "train_predict_shaped = train_predict_shaped[:,4:5]\n",
    "print(test_predict_shaped.shape)\n",
    "print(train_predict_shaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = mean_squared_error(y_train[:,0,4], train_predict[:,4])\n",
    "test_mse = mean_squared_error(y_test[:,0,4], test_predict[:,4])\n",
    "# calculate mean squared error\n",
    "print('Train Score: %.2f RMSE' % (train_mse))\n",
    "print('Test Score: %.2f RMSE' % (test_mse))\n",
    "\n",
    "# calculate root mean squared error\n",
    "print('Train Score: %.2f RMSE' % (math.sqrt(train_mse)))\n",
    "print('Test Score: %.2f RMSE' % (math.sqrt(test_mse)))\n",
    "\n",
    "# calculate root mean abs error\n",
    "print('Train Score: %.2f MAE' % (mean_absolute_error(y_train[:,0,4], train_predict[:,4])))\n",
    "print('Test Score: %.2f MAE' % (mean_absolute_error(y_test[:,0,4], test_predict[:,4])))\n",
    "\n",
    "# calculate root mean squared error\n",
    "print('Train Score: %.2f MAPE' % (mean_absolute_percentage_error(y_train[:,0,4], train_predict[:,4])))\n",
    "print('Test Score: %.2f MAPE' % (mean_absolute_percentage_error(y_test[:,0,4], test_predict[:,4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseData = scaler.inverse_transform(data)[:, 4:5]\n",
    "# initialize to length of base data\n",
    "trainPredictPlot = np.empty_like(baseData)\n",
    "# set all elements to nan\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "# shift train predictions by window length for plotting\n",
    "trainPredictPlot[look_back:len(train_predict_shaped)+look_back, :] = train_predict_shaped\n",
    "# initialize to length of base data\n",
    "testPredictPlot = np.empty_like(baseData)\n",
    "#set all elements to nan\n",
    "testPredictPlot[:, :] = np.nan\n",
    "#shift by length of training predictions plus \n",
    "testPredictPlot[len(train_predict_shaped)+(look_back*2)+1:len(baseData)-1, :] = test_predict_shaped[0:12901, :]\n",
    "# plot baseline and predictions\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.plot(baseData, '-', color='k', label='Close')\n",
    "plt.plot(trainPredictPlot, '-', color='g', label='Train Predicted Close')\n",
    "plt.plot(testPredictPlot, '-', color='r', label='Test Predicted Close')\n",
    "plt.legend(fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseTestData = scaler.inverse_transform(test_data)[:, 4:5]\n",
    "testPredictPlot2 = np.empty_like(baseTestData)\n",
    "testPredictPlot2[:, :] = np.nan\n",
    "testPredictPlot2[look_back:len(train_predict_shaped)+look_back, :] = test_predict_shaped\n",
    "# plot baseline and predictions\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.plot(baseTestData, '-', color='k', label='Close')\n",
    "plt.plot(testPredictPlot2, '-', color='r', label='Test Predicted Close')\n",
    "plt.legend(fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"C:\\ProgramData\\ETH\\Model\\model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"C:\\ProgramData\\ETH\\Model\\model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
